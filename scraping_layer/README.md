# Universal Scraping Layer

A comprehensive scraping system that handles both static and dynamic websites with direct script execution, intelligent strategy selection, and robust error handling.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Test basic scraping
python test_scraper.py https://example.com title=h1 description=p

# Test script execution layer
python test_script_execution.py

# Run advanced script tests
python scraping_layer/examples/test_script_execution_advanced.py --single
```

## ğŸ“ Project Structure

```
scraping_layer/
â”œâ”€â”€ __init__.py              # Main package exports
â”œâ”€â”€ models.py                # Data models and types
â”œâ”€â”€ interfaces.py            # Abstract interfaces
â”œâ”€â”€ engine.py                # Main orchestrator
â”œâ”€â”€ config.py                # Configuration management
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ script_execution/        # Direct script execution layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py            # Script execution models
â”‚   â””â”€â”€ executor.py          # Script executor
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logging.py           # Logging utilities
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ README.md            # Examples documentation
â”‚   â”œâ”€â”€ test_scraper.py      # Interactive test script
â”‚   â”œâ”€â”€ debug_scraper.py     # Debug and diagnostics
â”‚   â””â”€â”€ test_script_execution_advanced.py  # Advanced script tests
â””â”€â”€ docs/
    â”œâ”€â”€ USAGE.md             # Detailed usage guide
    â””â”€â”€ SCRIPT_EXECUTION.md  # Script execution documentation
```

## âœ¨ Features

### Current Implementation

- âœ… **Static website scraping** - HTTP requests + BeautifulSoup
- âœ… **CSS selector support** - Extract specific elements
- âœ… **Script execution layer** - Direct execution of pre-written scripts
- âœ… **Form-based script generation** - Convert form inputs to scraping scripts
- âœ… **Data cleaning** - HTML entity decoding, whitespace normalization
- âœ… **Error handling** - Graceful failure with detailed logging
- âœ… **Performance metrics** - Timing and extraction statistics
- âœ… **Execution history** - Track all scraping operations
- âœ… **Configuration system** - Environment-based configuration
- âœ… **Structured logging** - JSON logs with context
- âœ… **Testing framework** - Comprehensive test coverage

### Upcoming Features

- ğŸš§ **Dynamic website scraping** - Playwright browser automation
- ğŸš§ **Content detection** - Framework identification
- ğŸš§ **Anti-bot handling** - User agent rotation, delays
- ğŸš§ **Caching system** - Redis/memory-based caching
- ğŸš§ **Browser management** - Instance pooling and cleanup

## ğŸ§ª Testing

```bash
# Test basic scraping functionality
python test_scraper.py https://example.com

# Test script execution layer (form-based flow)
python test_script_execution.py

# Run advanced script execution tests
python scraping_layer/examples/test_script_execution_advanced.py

# Run single quick test
python scraping_layer/examples/test_script_execution_advanced.py --single

# Run unit tests
python -m pytest tests/ -v
```

## ğŸ“– Documentation

- **[Script Execution Guide](docs/SCRIPT_EXECUTION.md)** - Direct script execution documentation
- **[Usage Guide](docs/USAGE.md)** - Detailed usage instructions
- **[Examples](examples/README.md)** - Example scripts and patterns
- **[Requirements](../docs/kiro-spec.md)** - Original project specification

## ğŸ”§ Configuration

The scraping layer uses environment variables for configuration:

```bash
# Security settings
export SCRAPING_MAX_EXECUTION_TIME=300
export SCRAPING_MAX_MEMORY_MB=512

# Browser settings
export SCRAPING_MAX_BROWSERS=5
export SCRAPING_HEADLESS=true

# Cache settings
export SCRAPING_CACHE_BACKEND=memory
export SCRAPING_CACHE_TTL=3600

# Logging
export SCRAPING_LOG_LEVEL=INFO
```

## ğŸ—ï¸ Architecture

The system follows a layered architecture:

1. **API Layer** - ScrapingEngine (main interface)
2. **Detection Layer** - ContentDetector (website analysis)
3. **Execution Layer** - StaticScraper, DynamicScraper
4. **Support Services** - BrowserManager, CacheManager, ErrorHandler
5. **Data Layer** - DataExtractor, validation, cleaning

## ğŸ¤ Integration

The scraping layer integrates with form-based UIs and provides direct script execution:

```python
from scraping_layer.script_execution import ScrapingScript, ScriptExecutor
from scraping_layer.models import ScrapingStrategy

# Create script from form data
script = ScrapingScript(
    script_id="user_script_001",
    name="User Generated Script",
    description="Extract data based on user requirements",
    url="https://example.com",
    strategy=ScrapingStrategy.STATIC,
    selectors={"title": "h1", "content": "p"},
    expected_fields=["title", "content"]
)

# Execute script
executor = ScriptExecutor(scraping_engine)
result = await executor.execute_script(script)

# Use extracted data
if result.success:
    data = result.data
    # Serve via API endpoints or display in UI
```

## ğŸ“‹ Requirements

All dependencies are listed in the main project `requirements.txt` file.

**Core dependencies:**

- `requests` - HTTP client
- `beautifulsoup4` - HTML parsing
- `playwright` - Browser automation
- `aiohttp` - Async HTTP
- `pytest` - Testing framework

Install all dependencies from the project root:

```bash
pip install -r requirements.txt
```

## ğŸš¦ Status

**Script Execution Layer** âœ… **COMPLETE**

- Direct script execution without AI generation
- Form-based script creation
- Comprehensive error handling and validation
- Execution history tracking
- Integration with existing scraping engine

**Core Scraping Engine** âœ… **COMPLETE**

- Static website scraping
- CSS selector support
- Data cleaning and validation
- Performance metrics
- Configuration system

**Next Steps** - Dynamic scraping and browser automation

## ğŸ“„ License

Part of the AI API Generator project.
